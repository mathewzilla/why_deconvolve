\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Berens2018-su}
\citation{Theis2016-ee}
\citation{Berens2018-su}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Deneux2016-gu}
\citation{Pachitariu_undated-ui}
\citation{Deneux2016-gu}
\citation{Jewell2017-pr}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Deneux2016-gu}
\citation{Pachitariu_undated-ui}
\citation{Deneux2016-gu}
\citation{Jewell2017-pr}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Deneux2016-gu}
\citation{Pachitariu_undated-ui}
\citation{Deneux2016-gu}
\citation{Jewell2017-pr}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Deneux2016-gu}
\citation{Pachitariu_undated-ui}
\citation{Deneux2016-gu}
\citation{Jewell2017-pr}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Deneux2016-gu}
\citation{Pachitariu_undated-ui}
\citation{Deneux2016-gu}
\citation{Jewell2017-pr}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Deneux2016-gu}
\citation{Pachitariu_undated-ui}
\citation{Deneux2016-gu}
\citation{Jewell2017-pr}
\citation{Chen2013-nv}
\citation{Victor1996-cg}
\citation{Pachitariu_undated-ui}
\citation{Deneux2016-gu}
\citation{Jewell2017-pr}
\citation{Chen2013-nv}
\citation{Brown2004-tj,Paiva2010-qv,Theis2016-ee,Reynolds2017-dr,Berens2018-su}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Results}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Spike inference methods work well on ground truth data if parameters are fitted using Error Rate instead of Pearson Correlation Coefficient}{1}{subsection.2.1}}
\newlabel{GT}{{2.1}{1}{Spike inference methods work well on ground truth data if parameters are fitted using Error Rate instead of Pearson Correlation Coefficient}{subsection.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Ground truth data analysis. (a) Ground truth data collection example from \citet  {Chen2013-nv}. Top left, an example field of view from imaging data. Red lines denote the outline of a juxtacellular recording pipette. Time series shows measured calcium fluorescence (top) and simultaneously recorded voltage (below). Spikes are marked with asterisks. (b) Single spikes influence the calcium trace. (c) raw data (grey) and average (black) of single spike induced changes in fluorescence. (d) top: \cite  {Victor1996-cg} proposed a spike metric to compare spike trains. This metric is generated by determining the number of elementary operations (shift, addition or deletion of individual spikes - depicted as rows here) required to match two spike trains, up to some temporal precision. Bottom: In \citet  {Deneux2016-gu} the Error Rate (ER) is similarly computed as a normalised ratio of sensitivity vs precision in spike detection. Detections are counted to within 0.5s. (e) Correlation coefficient as a function of estimated firing rate (using Suite2P, \citet  {Pachitariu_undated-ui}). Colours are different cells. (f) as in (e) but with ER as a metric. (g) Estimated firing rate for `best' deconvolution parameters versus real firing rate. Best parameters are taken as the highest or lowest points in (e) and (f), respectively. (h) as in (g) but using MLSpike \citep  {Deneux2016-gu}. (i) as in (g) but using LZero \citep  {Jewell2017-pr}. (j) Normalised firing rate error (estimated FR - true FR / true FR) for all cells across all three methods. Lines are means. (a) reproduced from \citet  {Chen2013-nv}. (d) reproduced from \citet  {Victor1996-cg}. \emph  {MDH: Just need to bear in mind that we\IeC {\textquoteright }ll need a plan for replacing panels a-d with our own plots and schematics} }}{2}{figure.1}}
\newlabel{fig:GT_data}{{1}{2}{Ground truth data analysis. (a) Ground truth data collection example from \citet {Chen2013-nv}. Top left, an example field of view from imaging data. Red lines denote the outline of a juxtacellular recording pipette. Time series shows measured calcium fluorescence (top) and simultaneously recorded voltage (below). Spikes are marked with asterisks. (b) Single spikes influence the calcium trace. (c) raw data (grey) and average (black) of single spike induced changes in fluorescence. (d) top: \cite {Victor1996-cg} proposed a spike metric to compare spike trains. This metric is generated by determining the number of elementary operations (shift, addition or deletion of individual spikes - depicted as rows here) required to match two spike trains, up to some temporal precision. Bottom: In \citet {Deneux2016-gu} the Error Rate (ER) is similarly computed as a normalised ratio of sensitivity vs precision in spike detection. Detections are counted to within 0.5s. (e) Correlation coefficient as a function of estimated firing rate (using Suite2P, \citet {Pachitariu_undated-ui}). Colours are different cells. (f) as in (e) but with ER as a metric. (g) Estimated firing rate for `best' deconvolution parameters versus real firing rate. Best parameters are taken as the highest or lowest points in (e) and (f), respectively. (h) as in (g) but using MLSpike \citep {Deneux2016-gu}. (i) as in (g) but using LZero \citep {Jewell2017-pr}. (j) Normalised firing rate error (estimated FR - true FR / true FR) for all cells across all three methods. Lines are means. (a) reproduced from \citet {Chen2013-nv}. (d) reproduced from \citet {Victor1996-cg}. \emph {MDH: Just need to bear in mind that we’ll need a plan for replacing panels a-d with our own plots and schematics}}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Downsampled ground truth analysis. (a-c) Estimated firing rate for `best' deconvolution parameters versus real firing rate using Suite2P, MLSpike and LZero applied to ground truth data downsampled to 7Hz to more closely match population imaging experiments. (d) Normalised firing rate error (estimated FR - true FR / true FR) for all cells and across methods. Lines are means. }}{2}{figure.2}}
\newlabel{fig:GT_data_ds}{{2}{2}{Downsampled ground truth analysis. (a-c) Estimated firing rate for `best' deconvolution parameters versus real firing rate using Suite2P, MLSpike and LZero applied to ground truth data downsampled to 7Hz to more closely match population imaging experiments. (d) Normalised firing rate error (estimated FR - true FR / true FR) for all cells and across methods. Lines are means}{figure.2}{}}
\citation{Pachitariu_undated-ui}
\citation{Deneux2016-gu}
\citation{Victor1996-cg}
\citation{Peron2015-qz}
\citation{OConnor2010-hd,Wohrer2013-rp}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Best spike inference parameters varies across cells. X-axis: parameter value, Y-axis: cell ID (arbitrary but consistent order). Parameters for Suite2P (Threshold), MLSpike (A, tau, sigma) and LZero (lambda, scale) vary significantly across cells and sampling rates (rows), regardless of analysis metric (dot colour, ER: green, PCC: blue). }}{3}{figure.3}}
\newlabel{fig:GT_data_params}{{3}{3}{Best spike inference parameters varies across cells. X-axis: parameter value, Y-axis: cell ID (arbitrary but consistent order). Parameters for Suite2P (Threshold), MLSpike (A, tau, sigma) and LZero (lambda, scale) vary significantly across cells and sampling rates (rows), regardless of analysis metric (dot colour, ER: green, PCC: blue)}{figure.3}{}}
\citation{Deneux2016-gu,Victor1996-cg}
\citation{Theis2016-ee}
\citation{Reynolds2017-dr}
\citation{Peron2015-qz}
\citation{Peron2015-qz}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Variability in spike inference performance with changes in analysis parameters. (a) For each cell (colours) the estimated firing rate (y-axis) varies substantially across analysis parameters (dots). Dashed black line indicates correct estimated firing rate. (b) as in (a) for normalized estimated firing rate (Estimated FR/true FR). (c) Error rate increases sharply with small changes away from the best analysis parameters. (d) as in (c) showing a small region of parameter space around the best parameters). All results are from Suite2P applied to downsampled data as in Fig.\ref  {fig:GT_data_ds}. }}{4}{figure.4}}
\newlabel{fig:GT_param_performance}{{4}{4}{Variability in spike inference performance with changes in analysis parameters. (a) For each cell (colours) the estimated firing rate (y-axis) varies substantially across analysis parameters (dots). Dashed black line indicates correct estimated firing rate. (b) as in (a) for normalized estimated firing rate (Estimated FR/true FR). (c) Error rate increases sharply with small changes away from the best analysis parameters. (d) as in (c) showing a small region of parameter space around the best parameters). All results are from Suite2P applied to downsampled data as in Fig.\ref {fig:GT_data_ds}}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Spike inference and deconvolution methods disagree on estimates of simple neural statistics}{4}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  \citep  {Peron2015-qz} experimental design. TO DO EXPAND description once final figure arrangement is decided \emph  {MDH: Again, we need to think about how to remove or replace these figure panels for publication. We don\IeC {\textquoteright }t need the bottom rows of A-F here for example. For our purposes, we only care that there is a single recording of many neurons during a task. So versions of the bottom row G and H from the actual session we use would be good for the final version. We can redraw the top row A and C; For the parameters in top panel B, as far as I know these aren\IeC {\textquoteright }t used here (just \IeC {\textquotedblleft }touch\IeC {\textquotedblright }), so an be eliminated too. If we need them, then the redrawn A panel can have the angle and curvature parameters from B}}}{4}{figure.5}}
\newlabel{fig:peron_setup}{{5}{4}{\citep {Peron2015-qz} experimental design. TO DO EXPAND description once final figure arrangement is decided \emph {MDH: Again, we need to think about how to remove or replace these figure panels for publication. We don’t need the bottom rows of A-F here for example. For our purposes, we only care that there is a single recording of many neurons during a task. So versions of the bottom row G and H from the actual session we use would be good for the final version. We can redraw the top row A and C; For the parameters in top panel B, as far as I know these aren’t used here (just “touch”), so an be eliminated too. If we need them, then the redrawn A panel can have the angle and curvature parameters from B}}{figure.5}{}}
\citation{Peron2015-qz}
\citation{Peron2015-qz}
\citation{Yaksi2006-ic}
\citation{Peron2015-qz}
\citation{Wohrer2013-rp}
\citation{OConnor2010-hd}
\citation{Peron2015-qz}
\citation{OConnor2010-hd,Hires2015-by}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Different spike inference methods lead to different estimates of task related neurons}{5}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Deconvolution and spike inference may degrade the ability to recover precisely timed responses}{5}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Estimated `event rate' for all cells in an example session. For the first 6 methods (Calcium - LZero$_{kernel}$), events are detected as fluorescence transients greater in magnitude than 3 std deviations of background noise. Background noise = data - smoothed version of data, to eliminate slow transients. Methods 7-9 (Suite2P$_{events}$ - LZero$_{events}$) return a spike count per time bin. (a) Histograms of event rate per cell for each method. (b) Same data as in (a) but plotted as box and whisker plots. Notch = median, box limits = 25th and 75th percentile, whiskers = extent of data up to 1.5 IQR (c) Proportion of active (gray) vs silent (black) cells for each method. Silent = event rate < 0.0083Hz.}}{6}{figure.6}}
\newlabel{fig:simple_stats}{{6}{6}{Estimated `event rate' for all cells in an example session. For the first 6 methods (Calcium - LZero$_{kernel}$), events are detected as fluorescence transients greater in magnitude than 3 std deviations of background noise. Background noise = data - smoothed version of data, to eliminate slow transients. Methods 7-9 (Suite2P$_{events}$ - LZero$_{events}$) return a spike count per time bin. (a) Histograms of event rate per cell for each method. (b) Same data as in (a) but plotted as box and whisker plots. Notch = median, box limits = 25th and 75th percentile, whiskers = extent of data up to 1.5 IQR (c) Proportion of active (gray) vs silent (black) cells for each method. Silent = event rate < 0.0083Hz}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Tuned cells. Tuned cells were determined through shuffle tests (following Peron et al 2015, see Methods). (a) Number of tuned cells per deconvolution method. Error bars are 95\% binomial confidence intervals (Jeffreys interval) (b) Agreement between methods. Bars show total number of cells classified as tuned by N methods. (c) Agreement between continuous signal methods (left) and spike inference methods (right). (d) Array of tuned cell identities, separately for continuous signal methods (left) and spike inference methods (right). Black = tuned, white = not tuned. Rows are cells, ordered by the number of methods that classify that cell as tuned (agreement, as plotted in c).}}{7}{figure.7}}
\newlabel{fig:tuned_cells}{{7}{7}{Tuned cells. Tuned cells were determined through shuffle tests (following Peron et al 2015, see Methods). (a) Number of tuned cells per deconvolution method. Error bars are 95\% binomial confidence intervals (Jeffreys interval) (b) Agreement between methods. Bars show total number of cells classified as tuned by N methods. (c) Agreement between continuous signal methods (left) and spike inference methods (right). (d) Array of tuned cell identities, separately for continuous signal methods (left) and spike inference methods (right). Black = tuned, white = not tuned. Rows are cells, ordered by the number of methods that classify that cell as tuned (agreement, as plotted in c)}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Degree of agreement between methods can identify strongly tuned cells. (a) Example normalised (z-score) trial-average histograms for 50 cells (rows) classified as tuned in an analysis of raw Calcium data. Each subsequent panel shows trial-average histograms for the same cells, but following processing by each of the eight deconvolution/spike inference methods. (b) - (d) as in (a) but showing trial-average data for cells classed as tuned by 3, 6 and all 9 methods. \textbf  {TO DO: Add marker to show which methods classify which cells as tuned?}}}{7}{figure.8}}
\newlabel{fig:tuned_cells_psth}{{8}{7}{Degree of agreement between methods can identify strongly tuned cells. (a) Example normalised (z-score) trial-average histograms for 50 cells (rows) classified as tuned in an analysis of raw Calcium data. Each subsequent panel shows trial-average histograms for the same cells, but following processing by each of the eight deconvolution/spike inference methods. (b) - (d) as in (a) but showing trial-average data for cells classed as tuned by 3, 6 and all 9 methods. \textbf {TO DO: Add marker to show which methods classify which cells as tuned?}}{figure.8}{}}
\citation{Ganmor2016-uf}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Touch-related responses. (a) Comparing touch-triggered average (mean deconvolved FR per imaging frame) from different deconvolution methods for one example cell. Touch occurs during frame 7 (dotted line). (b) Number of touch tuned cells varies across methods. A cell is classed as touch tuned if peak touch-triggered activity is significantly greater than shuffled data (Mann-Whitney U test, Benjamini Hochberg corrected). Error bars are Jeffreys intervals}}{8}{figure.9}}
\newlabel{fig:touch_triggered}{{9}{8}{Touch-related responses. (a) Comparing touch-triggered average (mean deconvolved FR per imaging frame) from different deconvolution methods for one example cell. Touch occurs during frame 7 (dotted line). (b) Number of touch tuned cells varies across methods. A cell is classed as touch tuned if peak touch-triggered activity is significantly greater than shuffled data (Mann-Whitney U test, Benjamini Hochberg corrected). Error bars are Jeffreys intervals}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Pairwise correlation distributions are affected by spike inference and deconvolution}{8}{subsection.2.5}}
\citation{Peron2015-kd}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Pairwise correlation distributions. (a) Pairwise correlations between all cells (y-axis) following processing with all deconvolution/spike inference methods (x-axis jitter added for clarity). Solid black lines are 5th, 50th and 95th percentiles. (b) Pairwise correlation kernel density functions for all methods. Vertical lines are medians and 5th, 50th and 95th percentiles. (c) and (d) as in (a) and (b) for different randomised versions of the data, to aid interpretation of distribution changes in (a) and (b).}}{9}{figure.10}}
\newlabel{fig:cxy_dist}{{10}{9}{Pairwise correlation distributions. (a) Pairwise correlations between all cells (y-axis) following processing with all deconvolution/spike inference methods (x-axis jitter added for clarity). Solid black lines are 5th, 50th and 95th percentiles. (b) Pairwise correlation kernel density functions for all methods. Vertical lines are medians and 5th, 50th and 95th percentiles. (c) and (d) as in (a) and (b) for different randomised versions of the data, to aid interpretation of distribution changes in (a) and (b)}{figure.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Deconvolution and spike inference results in different estimates of the dimensionality of population recordings}{9}{subsection.2.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces  PLACEHOLDER FIGURE. Lick induced dip in Ca\textsuperscript  {2+} fluorescence seen in the raw Calcium is also seen in deconvolved data.}}{9}{figure.13}}
\newlabel{fig:lick_PSTH}{{13}{9}{PLACEHOLDER FIGURE. Lick induced dip in Ca\textsuperscript {2+} fluorescence seen in the raw Calcium is also seen in deconvolved data}{figure.13}{}}
\citation{Theis2016-ee}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Pairwise correlations. (a) Example pairwise correlations for 50 cells. Some pairs of cells are consistently correlated across different methods (green arrow and boxes). Other pairs appear correlated when processed with one method but not with others (yellow arrow and boxes). (b) Correlation between pairwise correlation matrices for each method. Some methods result in similar correlation matrices (e.g. Yaksi and Calcium), while others generate distinct correlation matrices (LZero methods). (c) as in (b) but split to show continuous methods (left) or spike inference methods (right). \textbf  {add label to c saying 'spike inference' and 'continuous/de-noising'}}}{10}{figure.11}}
\newlabel{fig:cxy_comparison}{{11}{10}{Pairwise correlations. (a) Example pairwise correlations for 50 cells. Some pairs of cells are consistently correlated across different methods (green arrow and boxes). Other pairs appear correlated when processed with one method but not with others (yellow arrow and boxes). (b) Correlation between pairwise correlation matrices for each method. Some methods result in similar correlation matrices (e.g. Yaksi and Calcium), while others generate distinct correlation matrices (LZero methods). (c) as in (b) but split to show continuous methods (left) or spike inference methods (right). \textbf {add label to c saying 'spike inference' and 'continuous/de-noising'}}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Cumulative variance explained by N eigenvectors following Principal Components Analysis. Different spike inference/deconvolution methods result in different estimates of the dimensionality of the data. For example, 80$\%$ of the variance can be explained by 120 or 720 eigenvectors (orthogonal dimensions) depending on the processing method used. \emph  {FIX COLOURS: Can't tell which one is the calcium, which the $MLzero_{kernel}$, and which the $LZero_{events}$. Use grey for the raw Ca2+. MDH: To give some idea of how this tunes between \IeC {\textquotedblleft }low\IeC {\textquotedblright } and \IeC {\textquotedblleft }high\IeC {\textquotedblright } dimensions, replot these \IeC {\textquotedblleft }N\IeC {\textquotedblright } as a strip-plot (1D scatter) of the percentage of the population. The N=720 means we can\IeC {\textquoteright }t describe the data in much less than half the available dimensions = very high dimensional. Whereas the 120 = 10$\%$ of the available dimensions = low dimensional.}}}{10}{figure.12}}
\newlabel{fig:dimensionality}{{12}{10}{Cumulative variance explained by N eigenvectors following Principal Components Analysis. Different spike inference/deconvolution methods result in different estimates of the dimensionality of the data. For example, 80$\%$ of the variance can be explained by 120 or 720 eigenvectors (orthogonal dimensions) depending on the processing method used. \emph {FIX COLOURS: Can't tell which one is the calcium, which the $MLzero_{kernel}$, and which the $LZero_{events}$. Use grey for the raw Ca2+. MDH: To give some idea of how this tunes between “low” and “high” dimensions, replot these “N” as a strip-plot (1D scatter) of the percentage of the population. The N=720 means we can’t describe the data in much less than half the available dimensions = very high dimensional. Whereas the 120 = 10$\%$ of the available dimensions = low dimensional.}}{figure.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Discussion}{10}{section.3}}
\citation{Svoboda2015-ym}
\citation{Chen2013-nv}
\citation{Deneux2016-gu}
\citation{Victor1996-cg}
\citation{OConnor2010-hd}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{12}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Event rate estimation}{12}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Tuned cells}{12}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Touch-related responses}{12}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Pairwise correlations}{12}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Dimensionality}{13}{subsection.4.5}}
\bibstyle{plainnat}
\bibdata{references.bib}
\bibcite{Berens2018-su}{{1}{2018}{{Berens et~al.}}{{Berens, Freeman, Deneux, Chenkov, McColgan, Speiser, Macke, Turaga, Mineault, Rupprecht, Gerhard, Friedrich, Friedrich, Paninski, Pachitariu, Harris, Bolte, Machado, Ringach, Stone, Rogerson, Sofroniew, Reimer, Froudarakis, Euler, Rom{\'a}n~Ros{\'o}n, Theis, Tolias, and Bethge}}}
\bibcite{Brown2004-tj}{{2}{2004}{{Brown et~al.}}{{Brown, Kass, and Mitra}}}
\bibcite{Chen2013-nv}{{3}{2013}{{Chen et~al.}}{{Chen, Wardill, Sun, Pulver, Renninger, Baohan, Schreiter, Kerr, Orger, Jayaraman, Looger, Svoboda, and Kim}}}
\bibcite{Deneux2016-gu}{{4}{2016}{{Deneux et~al.}}{{Deneux, Kaszas, Szalay, Katona, Lakner, Grinvald, R{\'o}zsa, and Vanzetta}}}
\bibcite{Ganmor2016-uf}{{5}{2016}{{Ganmor et~al.}}{{Ganmor, Krumin, Rossi, Carandini, and Simoncelli}}}
\bibcite{Hires2015-by}{{6}{2015}{{Hires et~al.}}{{Hires, Gutnisky, Yu, O'Connor, and Svoboda}}}
\bibcite{Jewell2017-pr}{{7}{2017}{{Jewell and Witten}}{{}}}
\bibcite{OConnor2010-hd}{{8}{2010}{{O'Connor et~al.}}{{O'Connor, Peron, Huber, and Svoboda}}}
\bibcite{Pachitariu_undated-ui}{{9}{}{{Pachitariu et~al.}}{{Pachitariu, Stringer, Schr{\"o}der, Dipoppa, Federico~Rossi, Carandini, and Harris}}}
\bibcite{Paiva2010-qv}{{10}{2010}{{Paiva et~al.}}{{Paiva, Park, and Pr{\'\i }ncipe}}}
\bibcite{Peron2015-qz}{{11}{2015{a}}{{Peron et~al.}}{{Peron, Chen, and Svoboda}}}
\bibcite{Peron2015-kd}{{12}{2015{b}}{{Peron et~al.}}{{Peron, Freeman, Iyer, Guo, and Svoboda}}}
\bibcite{Reynolds2017-dr}{{13}{2017}{{Reynolds et~al.}}{{Reynolds, Schultz, and Dragotti}}}
\bibcite{Svoboda2015-ym}{{14}{2015}{{Svoboda}}{{}}}
\bibcite{Theis2016-ee}{{15}{2016}{{Theis et~al.}}{{Theis, Berens, Froudarakis, Reimer, Rom{\'a}n~Ros{\'o}n, Baden, Euler, Tolias, and Bethge}}}
\bibcite{Victor1996-cg}{{16}{1996}{{Victor and Purpura}}{{}}}
\bibcite{Wohrer2013-rp}{{17}{2013}{{Wohrer et~al.}}{{Wohrer, Humphries, and Machens}}}
\bibcite{Yaksi2006-ic}{{18}{2006}{{Yaksi and Friedrich}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Supplemental}{14}{section.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces Example datasets are long enough to generate stable correlation estimates. Correlation between the pairwise correlation matrix for a given method, and an equivalent correlation matrix for subsets of the data. For each datapoint in the figure a subset (1\%-100\%) of the full dataset is extracted at random without replacement and a matrix of pairwise correlations is generated. These correlations are then compared to the matching pairwise correlations in the full dataset. In all instances 20\% of the data is sufficient to recover correlations of 0.9, though there is substantial variation between methods.}}{14}{figure.1}}
\newlabel{fig:supp_cxy_stability}{{S1}{14}{Example datasets are long enough to generate stable correlation estimates. Correlation between the pairwise correlation matrix for a given method, and an equivalent correlation matrix for subsets of the data. For each datapoint in the figure a subset (1\%-100\%) of the full dataset is extracted at random without replacement and a matrix of pairwise correlations is generated. These correlations are then compared to the matching pairwise correlations in the full dataset. In all instances 20\% of the data is sufficient to recover correlations of 0.9, though there is substantial variation between methods}{figure.1}{}}
